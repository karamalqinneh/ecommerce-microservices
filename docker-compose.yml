version: '3.7'
services:
  mongodb_container:
    image: mongo:latest
    ports:
      - 27017:27017
    volumes:
      - mongodb_data_container:/data/db
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    platform: linux/x86_64
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: obsidiandynamics/kafka
    restart: "no"
    ports:
      - "9092:9092"
    environment:
      KAFKA_LISTENERS: "INTERNAL://:29092,EXTERNAL://:9092"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://broker:29092,EXTERNAL://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_ZOOKEEPER_SESSION_TIMEOUT: "6000"
      KAFKA_RESTART_ATTEMPTS: "10"
      KAFKA_RESTART_DELAY: "5"
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: "0"
    networks:
      - services


  #  config-server:
#    image: kqinneh/config-server:v1
#    container_name: config-server
#    platform: linux/x86_64
#    ports:
#      - "8888:8888"
#    expose:
#      - "8888"
#    healthcheck:
#      test: [ "CMD-SHELL", "curl -f http://localhost:8888/actuator/health || exit 1" ]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#    networks:
#      - services


  store-service:
    image: kqinneh/store-service:v1
#    pull_policy: always
    container_name: store-service
    platform: linux/x86_64
    environment:
      JAVA_TOOL_OPTIONS: "-javaagent:opentelemetry-javaagent-1.27.0.jar"
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317
      OTEL_METRICS_EXPORTER: none
      OTEL_SERVICE_NAME: "store-service"
#    environment:
#      - SPRING_PROFILES_ACTIVE=docker
    depends_on:
      - mongodb_container
      - service-registry
    restart: always
    networks:
      - services

  review-service:
#    pull_policy: always
    image: kqinneh/review-service:v1
    container_name: review-service
    platform: linux/x86_64
    environment:
      JAVA_TOOL_OPTIONS: "-javaagent:opentelemetry-javaagent-1.27.0.jar"
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317
      OTEL_METRICS_EXPORTER: none
      OTEL_SERVICE_NAME: "review-service"
#    environment:
#      - SPRING_PROFILES_ACTIVE=docker
    depends_on:
      - mongodb_container
      - broker
      - zookeeper
      - service-registry
    restart: always
    networks:
      - services

  service-registry:
#    pull_policy: always
    image: kqinneh/service-registry:v1
    container_name: service-registry
    platform: linux/x86_64
    environment:
      JAVA_TOOL_OPTIONS: "-javaagent:opentelemetry-javaagent-1.27.0.jar"
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317
      OTEL_METRICS_EXPORTER: none
      OTEL_SERVICE_NAME: "service-registry"
    ports:
      - "8761:8761"
#    expose:
#      - "8761"
        #    environment:
    #      - SPRING_PROFILES_ACTIVE=docker
    restart: always
    networks:
      - services

  notification-service:
#    pull_policy: always
    image: kqinneh/notification-service:v1
    container_name: notification-service
    platform: linux/x86_64
    environment:
      JAVA_TOOL_OPTIONS: "-javaagent:opentelemetry-javaagent-1.27.0.jar"
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317
      OTEL_METRICS_EXPORTER: none
      OTEL_SERVICE_NAME: "notification-service"
    #    environment:
    #      - SPRING_PROFILES_ACTIVE=docker
    depends_on:
      - mongodb_container
      - broker
      - zookeeper
      - service-registry
    restart: always
    networks:
      - services

  gateway-server:
#    pull_policy: always
    image: kqinneh/gateway-server:v1
    container_name: gateway-server
    platform: linux/x86_64
    environment:
      JAVA_TOOL_OPTIONS: "-javaagent:opentelemetry-javaagent-1.27.0.jar"
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317
      OTEL_METRICS_EXPORTER: none
      OTEL_SERVICE_NAME: "gateway-server"
    ports:
      - "8072:8072"
#    expose:
#      - "8072"
        #    environment:
#      - SPRING_PROFILES_ACTIVE=docker
#      - LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_SECURITY= TRACE
    depends_on:
      - store-service
      - review-service
      - notification-service
      - service-registry
    restart: always
    networks:
      - services

  read:
    image: grafana/loki:2.9.2
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ./evaluate-loki/loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns
      loki:
        aliases:
          - loki

  write:
    image: grafana/loki:2.9.2
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ./evaluate-loki/loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  promtail:
    image: grafana/promtail:2.9.2
    volumes:
      - ./evaluate-loki/promtail-local-config.yaml:/etc/promtail/config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      - gateway-server
    networks:
      - loki

  minio:
    image: minio/minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - loki

  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - services

  tempo:
    image: grafana/tempo
    container_name: tempo
    command: -config.file /etc/tempo-config.yml
    ports:
      - "3110:3100"
      - "4317:4317"
    volumes:
      - ./tempo/tempo.yml:/etc/tempo-config.yml
    networks:
      - services

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    depends_on:
      - gateway-server
    volumes:
      - ./grafana/datasource.yml:/etc/grafana/provisioning/datasources/datasource.yml
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
          - name: Loki
            type: loki
            access: proxy
            url: http://gateway:3100
            jsonData:
              httpHeaderName1: "X-Scope-OrgID"
            secureJsonData:
              httpHeaderValue1: "tenant1"
        EOF
        /run.sh
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - loki
      - services


networks:
  kafka-net:
    driver: bridge
  services:
    driver: bridge
  loki:

volumes:
  mongodb_data_container: